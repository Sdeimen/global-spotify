---
title: "INFO523 Decicion Trees"
author: "Sebastian Deimen & Noah Giebink"
date: "21 MÃ¤rz 2020"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# packages

#install.packages('xfun')
library(xfun)
libs <- c("rpart","rpart.plot","tidyverse", "adabag",  "rsample","ipred","randomForest","gbm","DMwR2")
#install.packages(libs)
xfun::pkg_attach(libs)

spot <- read.csv("spot_clean.csv")

```

At first, we are going to make two sets of our spot-data: one only related to the music vaiables and one also including the  socio- variables. 

```{r}
# preprocessing the data set 

spot_music <- spot %>% select(track.popularity, track.explicit, danceability, key, loudness, mode,
                        speechiness, acousticness, instrumentalness,
                        liveness, valence, tempo, country)

# trying another set of varibales due to horrible error rates for the first set
# I tried without track.popularity, makes it worse, so another try, including socio-variables

spot_music_socio <- spot %>% select(track.popularity, track.explicit, danceability, key, loudness, mode, 
                        speechiness, acousticness, instrumentalness,
                        liveness, valence, tempo, happiness, median_age, percent_urban, 
                        percent_internet_users, density_sqkm, freedom, gdp, country)
```


We splitted the spot_music_SOCIO data into training and test data, not using a validation set. 

```{r}
# splitting the data, two differnet ways: one with CreateDataPartition, second with sample

# first: 

split_index <- createDataPartition(spot_music_socio$country, p= 0.8, list = F)

spot_music_socio_train <- spot_music_socio[split_index,]
spot_music_socio_features_test <- spot_music_socio[-split_index, !(colnames(spot_music_socio) %in% c("country"))]
spot_music_socio_target_test <- spot_music_socio[-split_index, "country"]
  
  
# second:   
  
index <- sample(1:nrow(spot_music_socio),929)
train <- spot_music_socio[index,]
test <- spot_music_socio[-index,]


```

Our goal was to predict "country". We made a tree with the training data, used it to predict on our testdata and checked the results/error rates. The tree did surprisingly well with an error rate of 0 %. 

We also made a tree and prediction just for the music variables to predict "country", but the tree had a horrible error rate of  around 82 %. So we decided to choose a different approach. 

```{r}
# making two trees from different trainings sets

ct_create <- rpartXse(country ~ ., spot_music_socio_train, se=0.5)
ct_sample <- rpartXse(country ~ ., train, se=0.5)

# prediction using the trees

ps_create <- predict(ct_create, spot_music_socio_features_test, type = "class")
ps_sample <- predict(ct_sample, test, type = "class")

# have a look at the variable.importance
ct_create$variable.importance
ct_sample$variable.importance

# contingency tables
cm_create <- table(ps_create, spot_music_socio_target_test)
cm_sample <- table(ps_sample,test$country)

# error rate
error_create <- (1-sum(diag(cm_create))/sum(cm_create))
cat(" error_create rate: ",error_create)
                    
error_sample <- (1-sum(diag(cm_sample))/sum(cm_sample))
cat(" error_sample rate: ",error_sample)



```
```{r}
prp(ct_create, type = 1, extra = 103, roundint = FALSE)

```
The different approach: 
We clustered countries by most important social feature (happiness) for classification. We decided to use two k = 2 to get "happy" and "unhappy" countries. We then bound the clusters to our solely music-varibale data and used this to grow the tree. 

```{r}
set.seed(42)
hap <- spot_music_socio %>% group_by(country) %>% 
  summarise(happiness = mean(happiness))
hist(hap$happiness) # 2 modes, one (apparent) outlier

# cluster countries by happiness, 3 clusters
h <- kmeans(hap$happiness, 2)
h$cluster

spot_clust <- cbind(hap, h$cluster)
spot_clust <- rename(spot_clust, cluster = 'h$cluster')
arrange(spot_clust, cluster)

hi <- filter(spot_clust, cluster == 2) %>%
  select(country)
low <- filter(spot_clust, cluster == 1) %>%
  select(country)
#med <- filter(spot_clust, cluster == 3) %>%
  #select(country)

spot_music <- spot_music %>% mutate(cluster = 
                                      ifelse(country %in% hi$country,
                                             'high', 'low'))

#spot_music <- spot_music %>% mutate(cluster = ifelse(country %in% hi$country, 'high', 
#                                       ifelse(spot_music$country %in% med$country, 
#                                              'medium', 'low')))

#spot_music <- spot_music %>% 
#  group_by(country, cluster) %>% 
#  summarise_if(is.numeric, mean) %>%
#  ungroup(spot_music)
```


Splitting, growing, predicting and plotting for the different approach: 

```{r}
# get rid of country
spot_music2 <- select(spot_music, -country)

# splitting the data 
index_music <- sample(1:nrow(spot_music2),0.8*nrow(spot_music2))
train_music <- spot_music2[index_music,]
test_music <- spot_music2[-index_music,]




```

The spot_music trees and error rates:

```{r}
# making a tree
set.seed(42)
ct_music <- rpartXse(cluster ~ ., train_music, se=0.1)

# prediction using the trees

pred_music <- predict(ct_music, test_music, type = "class")

# have a look at the variable.importance
ct_music$variable.importance

# contingency tables
cm_music <- table(pred_music,test_music$cluster)

# error rate
error_music <- (1-sum(diag(cm_music))/sum(cm_music))
cat("error_sample rate: ",error_music)
```

Plot the tree
```{r}
prp(ct_music, type = 1, extra = 103, roundint = FALSE)

```


